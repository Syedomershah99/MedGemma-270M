# MedGemma-270M
This notebook fine‑tunes Gemma 3 (270M) on MIRIAD‑4.4M using Unsloth FastModel for faster &amp; lower‑VRAM training (QLoRA, Unsloth gradient checkpointing, sequence packing). It includes:  Chat‑template formatting for supervised fine‑tuning (SFT) TRL SFTTrainer (packing=True) for speed &amp; memory savings 
